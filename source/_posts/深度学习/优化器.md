---
title: 优化器
date: 2023-05-08 21:04:50
mathjax: true
---


## 总览
> 总览摘自[paddledoc](https://paddlepedia.readthedocs.io/en/latest/tutorials/deep_learning/optimizers/gd.html)


在NLP领域AdamW（AdamWeightDecayOptimizer）使用比较普遍，CV领域SGD和momentum使用比较普遍，推荐领域比较杂，强化学习领域Adam使用比较普遍。

|模型|优化器|领域|
|--|--|--|
|BERT|AdamWeightDecayOptimizer|NLP|
|ELECTRA|AdamWeightDecayOptimizer|NLP|
|XLNet|AdamWeightDecayOptimizer,AdamOptimizer|NLP|
|ZFNet|MomentumOptimizer|CV|
|VGGNet|SGD|CV|
|GoogLeNet|SGD|CV|
|ResNet|momentum|CV|
|EfficientNet|rmsprop|CV|
|DenseNet|Nesterov, momentum|CV|
|Faster R-CNN|momentum|CV|
|Mask R-CNN|SGD|CV|
|YOLOv3,YOLOv5|Adam,SGD|CV|
|RetinaNet|SGD|CV|
|YoutubeDNN|Adam|RS|
|DSSM|adagrad|RS|
|DeepFM|adam,adagrad,gd,momentum|RS|
|DQN|Adam|RL|
|DDPG|Adam|RL|
|A2C|Adam|RL|


## Momentum
为了抑制SGD的震荡，SGDM认为梯度下降过程可以加入惯性。可以简单理解为：当我们将一个小球从山上滚下来时，没有阻力的话，它的动量会越来越大，但是如果遇到了阻力，速度就会变小。SGDM全称是SGD with momentum，在SGD基础上引入了一阶动量：


Momentum优化器是一种基于梯度的优化算法，与标准的随机梯度下降（SGD）算法相比，Momentum优化器在更新参数时增加了一个动量项，以使得参数更新更加平滑和稳定。Momentum优化器的公式如下：

$$
\begin{aligned}
\mathbf{v}_t &= \beta \mathbf{v}_{t-1} + (1 - \beta) \nabla_{\mathbf{\theta}} J(\mathbf{\theta}) \\
\mathbf{\theta}_t &= \mathbf{\theta}_{t-1} - \alpha \mathbf{v}_t
\end{aligned}
$$

其中，$\mathbf{\theta}$ 表示需要优化的参数向量，$J(\mathbf{\theta})$ 表示损失函数，$\nabla_{\mathbf{\theta}} J(\mathbf{\theta})$ 表示损失函数关于参数的梯度，$\alpha$ 表示学习率，$\beta$ 是动量因子，$\mathbf{v}$ 是动量项向量。

在Momentum优化器中，动量项 $\mathbf{v}$ 起到一个平滑器的作用，使得梯度的方向更加稳定。动量因子 $\beta$ 通常设置为一个较小的值，如0.9或0.99，以平衡动量项的影响。在更新参数时，动量项和梯度的加权和被用于更新参数向量 $\mathbf{\theta}$。

Momentum优化器的优点是可以减少梯度下降算法中的震荡，并使得梯度更新更加稳定，从而提高训练的效率和性能。

## 自适应梯度优化器（Adaptive Gradient,Adagrad）



自适应梯度优化器（Adaptive Gradient Optimizer，AdaGrad）是一种基于梯度的优化算法，它使用每个参数的历史梯度信息来调整学习率，以提高模型的收敛速度和效果。AdaGrad的公式如下：

$$
\begin{aligned}
\mathbf{g}_t &= \nabla_{\mathbf{\theta}} J(\mathbf{\theta}) \\
\mathbf{s}_t &= \sum_{i=1}^t \mathbf{g}_i \odot \mathbf{g}_i \\
\mathbf{\theta}_t &= \mathbf{\theta}_{t-1} - \frac{\alpha}{\sqrt{\mathbf{s}_t + \epsilon}} \odot \mathbf{g}_t
\end{aligned}
$$

其中，$\mathbf{\theta}$ 表示需要优化的参数向量，$J(\mathbf{\theta})$ 表示损失函数，$\nabla_{\mathbf{\theta}} J(\mathbf{\theta})$ 表示损失函数关于参数的梯度，$\alpha$ 表示学习率，$\mathbf{g}$ 表示梯度向量，$\odot$ 表示向量的逐元素乘积，$\mathbf{s}$ 是历史梯度平方和的累积向量，$\epsilon$ 是为了数值稳定而添加的一个小常数。

在AdaGrad中，每个参数的学习率都是动态调整的，它与历史梯度的平方和成反比。这意味着对于具有较大历史梯度平方和的参数，学习率将变得更小，以避免过度更新。另一方面，对于具有较小历史梯度平方和的参数，学习率将变得更大，以提高收敛速度。

AdaGrad的优点是可以自适应地调整每个参数的学习率，适应不同参数的梯度分布。但是，AdaGrad在处理稀疏梯度时存在问题，因为历史梯度平方和的累积可能导致学习率过小。因此，AdaGrad的改进算法，如RMSprop和Adam，被广泛应用于深度学习中。

## 自适应矩估计优化器（Adaptive Moment Estimation，Adam）

> 相对于AdaGrad，RMSprop使用指数加权移动平均的方式估计梯度的方差，从而调整每个参数的学习率


自适应矩估计优化器（Root Mean Square Propagation，RMSprop）是一种基于梯度的优化算法，它使用指数加权移动平均（Exponential Moving Average，EMA）的方式估计梯度的方差，从而调整每个参数的学习率。RMSprop的公式如下：

$$
\begin{aligned}
\mathbf{g}_t &= \nabla_{\mathbf{\theta}} J(\mathbf{\theta}) \\
\mathbf{s}_t &= \beta \mathbf{s}_{t-1} + (1 - \beta) \mathbf{g}_t \odot \mathbf{g}_t \\
\mathbf{\theta}_t &= \mathbf{\theta}_{t-1} - \frac{\alpha}{\sqrt{\mathbf{s}_t + \epsilon}} \odot \mathbf{g}_t
\end{aligned}
$$

其中，$\mathbf{\theta}$ 表示需要优化的参数向量，$J(\mathbf{\theta})$ 表示损失函数，$\nabla_{\mathbf{\theta}} J(\mathbf{\theta})$ 表示损失函数关于参数的梯度，$\alpha$ 表示学习率，$\mathbf{g}$ 表示梯度向量，$\odot$ 表示向量的逐元素乘积，$\mathbf{s}$ 是历史梯度平方的指数加权平均，$\epsilon$ 是为了数值稳定而添加的一个小常数，$\beta$ 是指数加权平均的系数，通常取值为0.9。

在RMSprop中，每个参数的学习率是自适应调整的，它与历史梯度平方的指数加权平均的平方根成反比。这意味着对于具有较大历史梯度平方的参数，学习率将变得更小，以避免过度更新。另一方面，对于具有较小历史梯度平方的参数，学习率将变得更大，以提高收敛速度。

RMSprop的优点是可以自适应地调整每个参数的学习率，并且能够有效地处理稀疏梯度。此外，RMSprop相对于AdaGrad和Momentum等算法具有更快的收敛速度。但是，RMSprop仍然存在某些限制，如难以处理非凸函数和鞍点问题等。因此，在实际应用中，可以结合其他优化算法进行改进，如Adam等。

## adamW
> AdamW本质上就是在损失函数里面加入了L2正则项，然后计算梯度和更新参数的时候都需要考虑这个正则项


AdamW是一种基于Adam优化器的变种，它在Adam优化器的基础上增加了权重衰减（weight decay）的正则化项，以避免过拟合。AdamW的公式如下：

$$
\begin{aligned}
\mathbf{g}_t &= \nabla_{\mathbf{\theta}} J(\mathbf{\theta}) \\
\mathbf{m}_t &= \beta_1 \mathbf{m}_{t-1} + (1 - \beta_1) \mathbf{g}_t \\
\mathbf{v}_t &= \beta_2 \mathbf{v}_{t-1} + (1 - \beta_2) \mathbf{g}_t \odot \mathbf{g}_t \\
\hat{\mathbf{m}}_t &= \frac{\mathbf{m}_t}{1 - \beta_1^t} \\
\hat{\mathbf{v}}_t &= \frac{\mathbf{v}_t}{1 - \beta_2^t} \\
\mathbf{\theta}_t &= \mathbf{\theta}_{t-1} - \frac{\alpha}{\sqrt{\hat{\mathbf{v}}_t} + \epsilon} \odot \hat{\mathbf{m}}_t - \lambda \mathbf{\theta}_{t-1}
\end{aligned}
$$

其中，$\mathbf{\theta}$ 表示需要优化的参数向量，$J(\mathbf{\theta})$ 表示损失函数，$\nabla_{\mathbf{\theta}} J(\mathbf{\theta})$ 表示损失函数关于参数的梯度，$\alpha$ 表示学习率，$\mathbf{g}$ 表示梯度向量，$\odot$ 表示向量的逐元素乘积，$\beta_1$ 和 $\beta_2$ 分别是一阶和二阶矩的指数加权平均系数，通常取值为0.9和0.999，$\mathbf{m}$ 和 $\mathbf{v}$ 分别表示一阶和二阶矩的指数加权平均值，$\hat{\mathbf{m}}$ 和 $\hat{\mathbf{v}}$ 分别表示经过偏差修正后的一阶和二阶矩估计值，$\epsilon$ 是为了数值稳定而添加的一个小常数，$\lambda$ 是权重衰减的系数。


权重衰减是一种正则化技术，用于控制模型复杂度和避免过拟合。它通过向损失函数添加一个正则化项，惩罚参数的大小，从而鼓励模型使用较小的权重来表示数据。

具体来说，权重衰减的正则化项是指在优化目标中添加一个惩罚项，以防止参数取值过大。它通常表示为$L_2$正则化项，形式如下：

$$
\mathcal{L}_{reg} = \frac{\lambda}{2}\sum_{i=1}^{n}\|\mathbf{w}_i\|^2
$$

其中，$\mathbf{w}_i$ 表示模型的第 $i$ 个参数，$\lambda$ 是正则化系数，用于控制正则化的强度。


